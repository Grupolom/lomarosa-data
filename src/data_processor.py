"""
MÃ³dulo de Procesamiento de Datos - Dashboard Inventario Lomarosa
Incluye anÃ¡lisis con datos histÃ³ricos de ventas
ACTUALIZADO: Carga datos desde SharePoint/OneDrive usando enlaces compartidos
"""

import os
import pandas as pd
import numpy as np
from datetime import datetime
import config
import warnings

# Importar SharePointLoader solo si estÃ¡ habilitado
if config.USE_SHAREPOINT:
    try:
        from sharepoint_loader import SharePointLoader
    except ImportError:
        print("âš ï¸ No se pudo importar SharePointLoader. Modo SharePoint desactivado.")
        config.USE_SHAREPOINT = False

warnings.filterwarnings('ignore')


class DataProcessor:
    """Clase para procesar los datos del inventario y ventas histÃ³ricas"""
    
    def __init__(self, excel_path=None):
        """
        Inicializa el procesador de datos
        
        Args:
            excel_path: Ruta local del Excel (solo para modo local)
        """
        self.excel_path = excel_path or config.EXCEL_PATH
        self.use_sharepoint = config.USE_SHAREPOINT
        self.sharepoint_loader = None
        
        self.df = None
        self.df_processed = None
        self.df_historical = None
        self.promedios = None
        self.analisis = None
        
        # Inicializar SharePoint si estÃ¡ habilitado
        if self.use_sharepoint:
            try:
                print("ðŸŒ Iniciando conexiÃ³n con SharePoint Online...")
                self.sharepoint_loader = SharePointLoader()
                print("âœ… Modo: Carga desde SharePoint Online activado")
            except Exception as e:
                print(f"âš ï¸ Error al inicializar SharePoint: {str(e)}")
                print("âš ï¸ Fallback: cambiando a modo local")
                self.use_sharepoint = False
        
        if not self.use_sharepoint:
            print("ðŸ’¾ Modo: Carga desde archivos locales")
    
    def load_data(self):
        """Carga los datos desde SharePoint/OneDrive o archivo local"""
        try:
            if self.use_sharepoint and self.sharepoint_loader:
                # âœ¨ CARGAR DESDE SHAREPOINT/ONEDRIVE (enlaces compartidos)
                print(f"\nðŸ“‚ Cargando inventario desde SharePoint/OneDrive...")
                
                self.df = self.sharepoint_loader.load_excel_from_sharepoint(
                    file_type='inventario',
                    sheet_name=config.SHEET_NAME,
                    skiprows=9
                )
                
            else:
                # CARGAR DESDE LOCAL (cÃ³digo original)
                print(f"\nðŸ“‚ Cargando inventario desde archivo local...")
                print(f"   Ruta: {self.excel_path}")
                
                if not os.path.exists(self.excel_path):
                    print(f"âŒ El archivo no existe en la ruta: {self.excel_path}")
                    return False
                
                self.df = pd.read_excel(
                    self.excel_path,
                    sheet_name=config.SHEET_NAME,
                    skiprows=9,
                    engine='openpyxl'
                )
            
            self.df.columns = self.df.columns.str.strip()
            
            print(f"âœ… Inventario cargado: {len(self.df)} filas")
            print(f"ðŸ“‹ Columnas: {list(self.df.columns)}")
            return True
            
        except Exception as e:
            print(f"âŒ Error al cargar inventario: {str(e)}")
            import traceback
            traceback.print_exc()
            return False
    
    def load_historical_data(self):
        """Carga datos histÃ³ricos desde SharePoint/OneDrive o archivo local"""
        try:
            if self.use_sharepoint and self.sharepoint_loader:
                # âœ¨ CARGAR DESDE SHAREPOINT/ONEDRIVE (enlaces compartidos)
                print(f"\nðŸ“Š Cargando consolidado desde SharePoint/OneDrive...")
                
                self.df_historical = self.sharepoint_loader.load_excel_from_sharepoint(
                    file_type='consolidado',
                    sheet_name=config.CONSOLIDADO_SHEET,
                    skiprows=0
                )
                
            else:
                # CARGAR DESDE LOCAL (cÃ³digo original)
                print(f"\nðŸ“Š Cargando consolidado desde archivo local...")
                
                if not os.path.exists(config.CONSOLIDADO_PATH):
                    print(f"âš ï¸ No se encontrÃ³ archivo histÃ³rico: {config.CONSOLIDADO_PATH}")
                    return False
                
                self.df_historical = pd.read_excel(
                    config.CONSOLIDADO_PATH,
                    sheet_name=config.CONSOLIDADO_SHEET,
                    engine='openpyxl'
                )
            
            print(f"âœ… Consolidado cargado: {len(self.df_historical)} registros")
            return True
            
        except Exception as e:
            print(f"âš ï¸ Error al cargar consolidado: {str(e)}")
            import traceback
            traceback.print_exc()
            return False
    
    def clean_data(self):
        """Limpia y prepara los datos de inventario"""
        if self.df is None:
            print("âŒ No hay datos cargados")
            return False
        
        try:
            print("ðŸ§¹ Limpiando datos de inventario...")
            
            df = self.df.copy()
            
            # Encontrar columna de cÃ³digo
            codigo_columns = [col for col in df.columns if 'cod' in col.lower()]
            if not codigo_columns:
                print("âŒ No se encontrÃ³ columna de cÃ³digo")
                return False
            
            codigo_col = codigo_columns[0]
            print(f"ðŸ“Œ Usando columna '{codigo_col}' como cÃ³digo")
            
            # Convertir Total a numÃ©rico
            df['Total'] = pd.to_numeric(df['Total'], errors='coerce')
            
            # Eliminar filas sin cÃ³digo o total
            df = df.dropna(subset=[codigo_col, 'Total'])
            df = df[df['Total'] > 0].copy()
            
            # Normalizar cÃ³digos a enteros
            df[codigo_col] = pd.to_numeric(df[codigo_col], errors='coerce')
            df[codigo_col] = df[codigo_col].astype('Int64')
            df = df[df[codigo_col].notna()]
            
            # Seleccionar y renombrar columnas
            inventario_procesado = df[[codigo_col, 'Productos', 'Total']].copy()
            inventario_procesado = inventario_procesado.rename(columns={
                codigo_col: 'Codigo',
                'Productos': 'Producto',
                'Total': 'Stock_Actual'
            })
            
            # Crear categorÃ­as de stock
            inventario_procesado['categoria_stock'] = inventario_procesado['Stock_Actual'].apply(self._categorizar_stock)
            inventario_procesado['categoria_producto'] = inventario_procesado['Producto'].apply(self._categorizar_producto)
            inventario_procesado['disponible'] = inventario_procesado['Stock_Actual'] > 0
            
            self.df_processed = inventario_procesado
            print(f"âœ… Datos limpiados: {len(inventario_procesado)} productos procesados")
            return True
            
        except Exception as e:
            print(f"âŒ Error al limpiar datos: {str(e)}")
            import traceback
            traceback.print_exc()
            return False
    
    def process_historical_sales(self):
        """Procesa datos histÃ³ricos de ventas"""
        if self.df_historical is None:
            print("âš ï¸ No hay datos histÃ³ricos para procesar")
            return False
        
        try:
            print("ðŸ”„ Procesando ventas histÃ³ricas...")
            
            df_hist = self.df_historical.copy()
            
            # Normalizar columnas
            df_hist['Doc'] = df_hist['Doc'].astype(str).str.strip().str.upper()
            df_hist['Local'] = df_hist['Local'].astype(str).str.strip().str.upper()
            
            # Filtrar por VENTA y PLANTA GALAN
            ventas = df_hist[
                (df_hist['Doc'] == config.FILTRO_DOC_TIPO) & 
                (df_hist['Local'] == config.FILTRO_LOCAL)
            ].copy()
            
            print(f"ðŸ“Œ Registros despuÃ©s de filtros: {len(ventas)}")
            
            # Normalizar cÃ³digos
            ventas[config.COL_COD_HISTORICO] = pd.to_numeric(ventas[config.COL_COD_HISTORICO], errors='coerce')
            ventas[config.COL_COD_HISTORICO] = ventas[config.COL_COD_HISTORICO].astype('Int64')
            ventas = ventas[ventas[config.COL_COD_HISTORICO].notna()]
            
            # Seleccionar columnas relevantes
            ventas_procesadas = ventas[[config.COL_FECHA, config.COL_COD_HISTORICO, config.COL_KG_VENDIDOS]].copy()
            ventas_procesadas = ventas_procesadas.rename(columns={
                config.COL_FECHA: 'fecha',
                config.COL_COD_HISTORICO: 'Cod',
                config.COL_KG_VENDIDOS: 'Kg_Vendidos'
            })
            
            # Calcular nÃºmero de semanas
            fecha_min = ventas_procesadas['fecha'].min()
            fecha_max = ventas_procesadas['fecha'].max()
            num_semanas = (fecha_max - fecha_min).days / 7
            
            print(f"ðŸ“… PerÃ­odo: {fecha_min.strftime('%d/%m/%Y')} a {fecha_max.strftime('%d/%m/%Y')}")
            print(f"ðŸ“Š Total semanas: {num_semanas:.1f}")
            
            # Calcular promedios semanales
            promedios = ventas_procesadas.groupby('Cod').agg({
                'Kg_Vendidos': ['sum', 'count']
            }).reset_index()
            
            promedios.columns = ['Cod', 'Total_Vendido', 'Num_Ventas']
            promedios['Promedio_Semanal'] = promedios['Total_Vendido'] / num_semanas
            
            self.promedios = promedios
            print(f"âœ… Promedios calculados para {len(promedios)} productos")
            return True
            
        except Exception as e:
            print(f"âŒ Error al procesar ventas: {str(e)}")
            import traceback
            traceback.print_exc()
            return False
    
    def merge_with_historical(self):
        """Une inventario actual con promedios de ventas"""
        if self.df_processed is None or self.promedios is None:
            print("âš ï¸ No hay datos para combinar")
            return False
        
        try:
            print("ðŸ”— Combinando inventario con ventas...")
            
            # Convertir cÃ³digos a string para merge
            inventario = self.df_processed.copy()
            promedios = self.promedios.copy()
            
            inventario['Codigo'] = inventario['Codigo'].astype(str).str.strip().str.upper()
            promedios['Cod'] = promedios['Cod'].astype(str).str.strip().str.upper()
            
            # Merge con how='left' para mantener todos los productos
            analisis = pd.merge(
                inventario,
                promedios[['Cod', 'Total_Vendido', 'Num_Ventas', 'Promedio_Semanal']],
                left_on='Codigo',
                right_on='Cod',
                how='left'
            )
            
            # Rellenar NaN con 0
            analisis['Promedio_Semanal'] = analisis['Promedio_Semanal'].fillna(0)
            analisis['Total_Vendido'] = analisis['Total_Vendido'].fillna(0)
            analisis['Num_Ventas'] = analisis['Num_Ventas'].fillna(0)
            
            # Calcular estado
            analisis['Estado'] = np.where(
                analisis['Stock_Actual'] >= analisis['Promedio_Semanal'],
                'Stock Adecuado',
                'Bajo Promedio'
            )
            
            # Calcular diferencia
            analisis['Diferencia'] = analisis['Stock_Actual'] - analisis['Promedio_Semanal']
            
            # Calcular semanas de stock con casos especiales
            def calcular_semanas(row):
                stock = row['Stock_Actual']
                promedio = row['Promedio_Semanal']
                
                if stock < 0:
                    return -999
                if stock == 0:
                    return -1
                if promedio == 0 or pd.isna(promedio):
                    return -2
                return round(stock / promedio, 1)
            
            analisis['Semanas_Stock'] = analisis.apply(calcular_semanas, axis=1)
            
            # Agregar Macropieza desde el consolidado
            if self.df_historical is not None:
                df_hist = self.df_historical.copy()
                df_hist['Cod'] = df_hist['Cod'].astype(str).str.strip().str.upper()
                macropieza_map = df_hist.groupby('Cod')['Macropieza'].first().to_dict()
                analisis['Macropieza'] = analisis['Codigo'].map(macropieza_map)
                analisis['Macropieza'] = analisis['Macropieza'].fillna('Sin clasificar')
                print(f"âœ… Macropiezas agregadas: {analisis['Macropieza'].nunique()} categorÃ­as")
            
            # Eliminar columna duplicada
            if 'Cod' in analisis.columns:
                analisis = analisis.drop('Cod', axis=1)
            
            self.analisis = analisis
            print(f"âœ… Datos combinados exitosamente: {len(analisis)} productos")
            return True
            
        except Exception as e:
            print(f"âŒ Error al combinar datos: {str(e)}")
            import traceback
            traceback.print_exc()
            return False
    
    def _categorizar_stock(self, cantidad):
        """Categoriza el nivel de stock"""
        if cantidad == 0:
            return "Sin Stock"
        elif cantidad <= config.STOCK_CRITICO:
            return "CrÃ­tico"
        elif cantidad <= config.STOCK_BAJO:
            return "Bajo"
        else:
            return "Normal"
    
    def _categorizar_producto(self, nombre):
        """Categoriza productos por tipo"""
        nombre = nombre.upper()
        
        if 'CHULETA' in nombre:
            return 'Chuletas'
        elif 'COSTILLA' in nombre or 'COSTILOMO' in nombre:
            return 'Costillas'
        elif 'CANASTO' in nombre:
            return 'Canastos'
        elif 'MERMA' in nombre:
            return 'Mermas'
        elif 'SILLA' in nombre:
            return 'Sillas'
        elif 'SPARRY' in nombre:
            return 'Sparry'
        elif 'MATAMBRITO' in nombre:
            return 'Matambrito'
        elif 'COSTIPIEL' in nombre:
            return 'Costipiel'
        else:
            return 'Otros'
    
    def get_statistics(self):
        """Calcula estadÃ­sticas del inventario"""
        if self.df_processed is None:
            return None
        
        df = self.df_processed
        
        stats = {
            'total_productos': len(df),
            'productos_disponibles': df['disponible'].sum(),
            'productos_sin_stock': (~df['disponible']).sum(),
            'porcentaje_disponibilidad': (df['disponible'].sum() / len(df) * 100) if len(df) > 0 else 0,
            'stock_total_kilos': df['Stock_Actual'].sum(),
            'productos_criticos': (df['categoria_stock'] == 'CrÃ­tico').sum(),
            'productos_bajo_stock': (df['categoria_stock'] == 'Bajo').sum(),
            'fecha_actualizacion': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        if self.analisis is not None:
            stats['stock_adecuado'] = len(self.analisis[self.analisis['Estado'] == 'Stock Adecuado'])
            stats['bajo_promedio'] = len(self.analisis[self.analisis['Estado'] == 'Bajo Promedio'])
            stats['productos_sin_ventas'] = len(self.analisis[self.analisis['Num_Ventas'] == 0])
        
        return stats
    
    def get_data_by_category(self):
        """Obtiene datos agrupados por categorÃ­a"""
        if self.df_processed is None:
            return None
        
        df = self.df_processed
        category_data = df.groupby('categoria_producto').agg({
            'Stock_Actual': ['sum', 'count', 'mean'],
            'disponible': 'sum'
        }).round(2)
        category_data.columns = ['stock_total', 'num_productos', 'stock_promedio', 'productos_disponibles']
        category_data = category_data.reset_index()
        return category_data
    
    def get_critical_products(self):
        """Obtiene productos crÃ­ticos o sin stock"""
        if self.df_processed is None:
            return None
        
        df = self.df_processed
        critical = df[
            (df['categoria_stock'] == 'Sin Stock') | 
            (df['categoria_stock'] == 'CrÃ­tico')
        ].copy()
        critical = critical.sort_values('Stock_Actual')
        cols_to_show = ['Codigo', 'Producto', 'Stock_Actual', 'categoria_stock']
        return critical[cols_to_show]
    
    def get_top_sobrestock(self, n=10):
        """Obtiene productos con mayor sobrestock"""
        if self.analisis is None:
            return None
        return self.analisis.nlargest(n, 'Diferencia')
    
    def get_top_deficit(self, n=10):
        """Obtiene productos con mayor dÃ©ficit"""
        if self.analisis is None:
            return None
        return self.analisis.nsmallest(n, 'Diferencia')
    
    def get_top_rotacion(self, n=10):
        """Obtiene productos con mayor rotaciÃ³n"""
        if self.analisis is None:
            return None
        return self.analisis.nlargest(n, 'Num_Ventas')
    
    def get_productos_criticos_ventas(self, n=5):
        """Obtiene productos mÃ¡s crÃ­ticos segÃºn ratio de cobertura"""
        if self.analisis is None:
            return None
        
        criticos = self.analisis[
            (self.analisis['Promedio_Semanal'] > 0) & 
            (self.analisis['Stock_Actual'] < self.analisis['Promedio_Semanal'])
        ].copy()
        criticos['Ratio_Cobertura'] = criticos['Stock_Actual'] / criticos['Promedio_Semanal']
        return criticos.sort_values('Ratio_Cobertura').head(n)
    
    def process(self):
        """Ejecuta todo el proceso completo"""
        if not self.load_data():
            return False
        if not self.clean_data():
            return False
        
        if self.load_historical_data():
            if self.process_historical_sales():
                self.merge_with_historical()
        
        return True


if __name__ == "__main__":
    processor = DataProcessor()
    if processor.process():
        print("\nðŸ“Š EstadÃ­sticas:")
        stats = processor.get_statistics()
        for key, value in stats.items():
            print(f"  {key}: {value}")
